# TinyMAES

## Description
TinyMAES is a lightweight library for non-linear mono-objective optimisation
written in standard C using only the functions from the standard C library,
so it does not rely on external dependencies.

It uses the MA-ES evolution strategy algorithm, a variant of
[CMA-ES](http://cma.gforge.inria.fr/) without eigendecompostion of matrices.

The algorithm MA-ES is described in this article:
> "Simplify Your Covariance Matrix Adaptation Evolution Strategy"
> by Hans-Georg Beyer and Bernhard Sendhoff
> published in IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION, VOL. 21 no. 5, OCTOBER 2017

## Features
TinyMAES has been written so it can be easily embedded within an application.
It does not use any global variable, so it is possible to run multiple instance
of this algorithm in different threads. It uses its own Random Number Generator
and does not made any memory allocations after the initialisation call.

This library contains:
 * A Mersenne Twister Random Number Generator that is based on
   "Tables of 64-bit Mersenne Twisters" by T. Nishimura
   (published on ACM Transactions on Modeling and Computer Simulation 10. (2000)).
   Contrary to the reference implementation, it does not use global variables,
   so it is possible to run multiple instance of this generator in separates threads.
 * A heap sort function that is especially efficient when lambda >> mu.

## Programming interface
### Using MA-ES algorithm: `tinymaes.h`
The interface `tinymaes.h` defines a structure `TINYMAES_S` containing the state of the optimiser.
It is allocated using the call `TINYMAES_Create`

```C
TINYMAES_S *maes = TINYMAES_Create(nDimensions, lambda, mu, MAES_W_SUPERLINEAR, SEED);
```

With `nDimensions` the number of dimension of the search space, `lambda` the number
of individuals generated, `mu` the number of the best individuals selected.
The two other parameter are the weights `TINYMAES_WEIGHTS` that will make the evaluation strategy more
or less elitist, and the `SEED` that change the value generated by the random number generator.

For a same value of `SEED`, the algorithm shall produce the same values in a deterministic way.
If you want to launch multiple optimisation of a same problem, you should peak randomly a seed value.

The procedure `TINYMAES_NextStep` will generate at each step a new population of individual.
At the first call, we use a `NULL` array for generating the individual without updating the internal state.

```C
const double *X = TINYMAES_NextStep(maes, NULL);
```

The array `X` contains the population of individuals generated by the evolution strategy:
`x[(k-1)*nDimensions]`, ..., `x[k*nDimensions-1]` contains the real values of the k-th individual.

To process the evaluation strategy, we compute an array containing list of identifier
of the `mu` best individuals. The identifier of the first individual is `0`, and those of the k-th
individual is `k-1`.

This list can be obtained by using the function `heapsort_mu` that is declared in the `heapsort.h` header:

```C
heapsort_mu(F, nObjectives, lambda, idx, mu)
```

With `F` the array containing the `nObjectives` objectives functions associated to each individuals,
`idx` an array previously allocated for containing `mu` `int` integers.
The multiple objectives are sorted using lexicographic order, so the first objective could be the
most important constraints that are put to `0` when satisfied and the last one can be the
actual objective of the function.

Using this array of indices `idx`, we can update the parameter of the evolution strategy and
generate a new population of individuals using the command `TINYMAES_NextStep`:

```C
X = TINYMAES_NextStep(maes, idx);
```

Once the objective reached, the allocated structure must be freed with the procedure `TINYMAES_Free`.

